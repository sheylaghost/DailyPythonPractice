ğŸš€ Desafio Tech: Pipeline de NormalizaÃ§Ã£o e Chunking de Logs
Log Normalization and Chunking Pipeline

Atributo / Attribute	Detalhes / Details
NÃ­vel / Level	ğŸŸ  IntermediÃ¡rio Alto / High Intermediate
Tempo Estimado / Estimated Time	âˆ¼35Â min
Libs Permitidas / Allowed Libraries	os, re, json, datetime, itertools, collections

Exportar para as Planilhas

ğŸ‡§ğŸ‡· Contexto & Objetivo
Contexto ğŸ“–
VocÃª Ã© o engenheiro responsÃ¡vel por prÃ©-processar enormes logs de mÃºltiplos serviÃ§os, que chegam em formatos heterogÃªneos.

O objetivo deste desafio Ã© desenvolver uma soluÃ§Ã£o eficiente para:

Normalizar todas as entradas de log.

Agrupar as entradas em janelas temporais fixas.

Dividir os dados em chunks balanceados para processamento paralelo, priorizando o agrupamento temporal.

Objetivo TÃ©cnico ğŸ¯
Desenhar um mÃ³dulo eficiente em Python que, de forma modular e em streaming (usando geradores), consiga:

Varredura: Iterar sobre um diretÃ³rio de logs de tamanho arbitrÃ¡rio.

NormalizaÃ§Ã£o: Converter cada linha de log para o formato JSON: timestamp, service, level, message, meta.

Agrupamento: Organizar entradas em janelas temporais fixas (e.g., 5 minutos).

Chunking: Produzir chunks de saÃ­da de â‰ˆN entradas, mantendo o balanceamento por janela temporal.

ğŸ‡ºğŸ‡¸ Context & Objective
Context ğŸ“–
You are the engineer responsible for pre-processing enormous logs from multiple services, which arrive in heterogeneous formats.

The objective of this challenge is to develop an efficient solution to:

Normalize all log entries.

Group entries into fixed time windows.

Split the data into balanced chunks for parallel processing, prioritizing temporal grouping.

Technical Objective ğŸ¯
Design an efficient Python module that, in a modular and streaming fashion (using generators), can achieve the following:

Scanning: Iterate over a log directory of arbitrary size.

Normalization: Convert each log line to the JSON format: timestamp, service, level, message, meta.

Grouping: Organize entries into fixed time windows (e.g., 5 minutes).

Chunking: Produce output chunks of â‰ˆN entries, maintaining balance by time window.

ğŸš§ Regras e RestriÃ§Ãµes / Rules and Constraints
Usar apenas as bibliotecas nativas listadas no topo.

O processamento deve ser via streaming / geradores (nÃ£o carregar o arquivo inteiro na memÃ³ria).

A interface deve ser modular, com funÃ§Ãµes separadas e encadeadas para parsing, normalizaÃ§Ã£o, agrupamento e chunking.

O tratamento do timestamp deve ser manual/regex (sem usar dateutil).

Tratamento de erro: Entries malformadas devem ser desviadas para um dead-letter file.

ğŸ¤” Guia de RaciocÃ­nio (Mentoria) / Reasoning Guide (Mentoring)
EstratÃ©gia Principal: Utilize geradores (yield) em todas as etapas para garantir a eficiÃªncia de memÃ³ria (O(k)) e processar dados em tempo linear (O(n)).

Agrupamento Temporal: Calcule a chave da janela temporal usando a funÃ§Ã£o floor(timestamp/janela).

MemÃ³ria: Mantenha um buffer de janelas ativas e implemente uma lÃ³gica para "fechar" e liberar da memÃ³ria as janelas mais antigas que jÃ¡ foram processadas.
